{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 1 : Collecting Data from Twitter\n",
    "\n",
    "Due Date: 1/27/2020, **BEFORE the beginning of class at 11:00am**\n",
    "\n",
    "## **NOTE: There are *always* last minute issues submitting the case studies.  DO NOT WAIT UNTIL THE LAST MINUTE!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/en/thumb/9/9f/Twitter_bird_logo_2012.svg/220px-Twitter_bird_logo_2012.svg.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEAM Members:** Please EDIT this cell and add the names of all the team members in your team\n",
    "\n",
    "    member 1\n",
    "    \n",
    "    member 2\n",
    "    \n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Suggested Readings:** \n",
    "* Chapter 1 and Chapter 9 of the book \"Mining the Social Web\" can help a lot if you get stuck. \n",
    "* In fact, it is intentional that many of these questions can be answered directly from there (except for question 4)!\n",
    "* The idea is to ease you into the case studies :-)\n",
    "\n",
    "**Don't forget!**\n",
    "* You will need to install the python-twitter library to access the Twitter API\n",
    " * pip install python-twitter\n",
    "\n",
    "\n",
    "** NOTE **\n",
    "* **Please don't forget to save the notebook frequently when working in IPython Notebook, otherwise the changes you made can be lost**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Sampling Twitter Data with Either Streaming or Search API about a certain topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Select a topic that you are interested in, for example, \"WPI\" or \"Lady Gaga\"\n",
    "* Use Twitter Streaming API to sample a collection of tweets about this topic. (It would be recommended that the number of tweets should be larger than 200, but smaller than 1 million.\n",
    "* Store the tweets you downloaded into a local file (txt file or json file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"created_at\": \"Thu Jan 16 18:08:46 +0000 2020\",\n",
      " \"id\": 1217871328465838087,\n",
      " \"id_str\": \"1217871328465838087\",\n",
      " \"text\": \"Jamani claus vp mnaferi wpi shinyanga leo inaenda wiki sasa redio yenu haishiki kabisa vp\",\n",
      " \"truncated\": false,\n",
      " \"entities\": {\n",
      "  \"hashtags\": [],\n",
      "  \"symbols\": [],\n",
      "  \"user_mentions\": [],\n",
      "  \"urls\": []\n",
      " },\n",
      " \"metadata\": {\n",
      "  \"iso_language_code\": \"in\",\n",
      "  \"result_type\": \"recent\"\n",
      " },\n",
      " \"source\": \"<a href=\\\"http://twitter.com/download/iphone\\\" rel=\\\"nofollow\\\">Twitter for iPhone</a>\",\n",
      " \"in_reply_to_status_id\": 1217870960864481280,\n",
      " \"in_reply_to_status_id_str\": \"1217870960864481280\",\n",
      " \"in_reply_to_user_id\": 1207417749879832577,\n",
      " \"in_reply_to_user_id_str\": \"1207417749879832577\",\n",
      " \"in_reply_to_screen_name\": \"sulenga6\",\n",
      " \"user\": {\n",
      "  \"id\": 1207417749879832577,\n",
      "  \"id_str\": \"1207417749879832577\",\n",
      "  \"name\": \"sulenga\",\n",
      "  \"screen_name\": \"sulenga6\",\n",
      "  \"location\": \"\",\n",
      "  \"description\": \"Sulenga\",\n",
      "  \"url\": null,\n",
      "  \"entities\": {\n",
      "   \"description\": {\n",
      "    \"urls\": []\n",
      "   }\n",
      "  },\n",
      "  \"protected\": false,\n",
      "  \"followers_count\": 67,\n",
      "  \"friends_count\": 698,\n",
      "  \"listed_count\": 0,\n",
      "  \"created_at\": \"Wed Dec 18 21:50:39 +0000 2019\",\n",
      "  \"favourites_count\": 33,\n",
      "  \"utc_offset\": null,\n",
      "  \"time_zone\": null,\n",
      "  \"geo_enabled\": false,\n",
      "  \"verified\": false,\n",
      "  \"statuses_count\": 54,\n",
      "  \"lang\": null,\n",
      "  \"contributors_enabled\": false,\n",
      "  \"is_translator\": false,\n",
      "  \"is_translation_enabled\": false,\n",
      "  \"profile_background_color\": \"F5F8FA\",\n",
      "  \"profile_background_image_url\": null,\n",
      "  \"profile_background_image_url_https\": null,\n",
      "  \"profile_background_tile\": false,\n",
      "  \"profile_image_url\": \"http://pbs.twimg.com/profile_images/1207420234233192454/ceqnA9vm_normal.jpg\",\n",
      "  \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/1207420234233192454/ceqnA9vm_normal.jpg\",\n",
      "  \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/1207417749879832577/1576706462\",\n",
      "  \"profile_link_color\": \"1DA1F2\",\n",
      "  \"profile_sidebar_border_color\": \"C0DEED\",\n",
      "  \"profile_sidebar_fill_color\": \"DDEEF6\",\n",
      "  \"profile_text_color\": \"333333\",\n",
      "  \"profile_use_background_image\": true,\n",
      "  \"has_extended_profile\": false,\n",
      "  \"default_profile\": true,\n",
      "  \"default_profile_image\": false,\n",
      "  \"following\": false,\n",
      "  \"follow_request_sent\": false,\n",
      "  \"notifications\": false,\n",
      "  \"translator_type\": \"none\"\n",
      " },\n",
      " \"geo\": null,\n",
      " \"coordinates\": null,\n",
      " \"place\": null,\n",
      " \"contributors\": null,\n",
      " \"is_quote_status\": false,\n",
      " \"retweet_count\": 0,\n",
      " \"favorite_count\": 0,\n",
      " \"favorited\": false,\n",
      " \"retweeted\": false,\n",
      " \"lang\": \"in\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import twitter\n",
    "#---------------------------------------------\n",
    "# Define a Function to Login Twitter API\n",
    "def oauth_login():\n",
    "    # Prof. Paffenroth has a developer account for the class.  He will provide the Twitter access tokens for\n",
    "    # each team\n",
    "    # See https://developer.twitter.com/docs/auth/oauth for more information \n",
    "    # on Twitter's OAuth implementation.\n",
    "    \n",
    "    CONSUMER_KEY = 'S89y81Vg4KdrtJDFNaEUlBJp6'\n",
    "    CONSUMER_SECRET ='5W7yhtXwTidtgtGOOvwMX6ZW82Wo07ygSSxvphHnCNqy4QAoXg'\n",
    "    OAUTH_TOKEN = '571213367-LEBoB0uww7p9tmP3tyX2La4TuriGUUeWEBxGuPra'\n",
    "    OAUTH_TOKEN_SECRET = 'vAAzjHKyRK4PafTdjNAKAAVI5grqM92uWyHbMgmWvouZU'\n",
    "    \n",
    "    auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "                               CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    \n",
    "    twitter_api = twitter.Twitter(auth=auth)\n",
    "    return twitter_api\n",
    "\n",
    "twitter_api = oauth_login()\n",
    "\n",
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "import json\n",
    "def twitter_search(twitter_api, q, max_results=200, **kw):\n",
    "\n",
    "    # See http://bit.ly/2QyGz0P and https://bit.ly/2QyGz0P\n",
    "    # for details on advanced search criteria that may be useful for\n",
    "    # keyword arguments\n",
    "\n",
    "    # See https://dev.twitter.com/docs/api/1.1/get/search/tweets\n",
    "    search_results = twitter_api.search.tweets(q=q, count=100, **kw)\n",
    "\n",
    "    statuses = search_results['statuses']\n",
    "\n",
    "    # Iterate through batches of results by following the cursor until we\n",
    "    # reach the desired number of results, keeping in mind that OAuth users\n",
    "    # can \"only\" make 180 search queries per 15-minute interval. See\n",
    "    # https://developer.twitter.com/en/docs/basics/rate-limits\n",
    "    # for details. A reasonable number of results is ~1000, although\n",
    "    # that number of results may not exist for all queries.\n",
    "\n",
    "    # Enforce a reasonable limit\n",
    "    max_results = min(1000, max_results)\n",
    "\n",
    "    for _ in range(10): # 10*100 = 1000\n",
    "        try:\n",
    "            next_results = search_results['search_metadata']['next_results']\n",
    "        except KeyError as e: # No more results when next_results doesn't exist\n",
    "            break\n",
    "\n",
    "        # Create a dictionary from next_results, which has the following form:\n",
    "        # ?max_id=313519052523986943&q=NCAA&include_entities=1\n",
    "        kwargs = dict([ kv.split('=')\n",
    "                        for kv in next_results[1:].split(\"&\") ])\n",
    "\n",
    "        search_results = twitter_api.search.tweets(**kwargs)\n",
    "        statuses += search_results['statuses']\n",
    "\n",
    "        if len(statuses) > max_results:\n",
    "            break\n",
    "\n",
    "    return statuses\n",
    "\n",
    "# Sample usage\n",
    "\n",
    "twitter_api = oauth_login()\n",
    "\n",
    "q = \"WPI\"\n",
    "results = twitter_search(twitter_api, q, max_results=100)\n",
    "\n",
    "# Show one sample search result by slicing the list...\n",
    "print(json.dumps(results[0], indent=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report some statistics about the tweets you collected \n",
    "\n",
    "* The topic of interest: < INSERT YOUR TOPIC HERE>\n",
    "\n",
    "\n",
    "* The total number of tweets collected:  < INSERT THE NUMBER HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Analyzing Tweets and Tweet Entities with Frequency Analysis\n",
    "\n",
    "**1. Word Count:** \n",
    "* Use the tweets you collected in Problem 1, and compute the frequencies of the words being used in these tweets. \n",
    "* Plot a table of the top 30 words with their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('in', 239), ('RT', 150), ('to', 136), ('for', 129), ('is', 113), ('prices', 111), ('which', 111), ('be', 110), ('have', 109), ('#CPI', 107), (\"Dec'19\", 107), ('7.35%,due', 107), ('abnormal', 107), ('rise', 107), ('since', 107), ('cooled', 107), ('off&amp;will', 107), ('@Sanju_Verma_:', 106), ('#Onion', 106), ('reflected', 106)]\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "from collections import Counter\n",
    "\n",
    "words = []\n",
    "for status in results:\n",
    "    words += status['text'].split(' ')\n",
    "c = Counter(words)\n",
    "print(c.most_common(20))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Find the most popular tweets in your collection of tweets**\n",
    "\n",
    "Please plot a table of the top 10 tweets that are the most popular among your collection, i.e., the tweets with the largest number of retweet counts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Ankur_tiwari2: @ShekharGupta Retail inflation at 7.3% due to vegetable prices that should cool down. \n",
      "Core inflation still 3.7%. \n",
      "Under… 26\n",
      "RT @PaulFMatthews: Huge day for @WPI @UMassMedical @Mass_Tech @GEHealthcare @MITREcorp &amp; @NIH @TweetWorcester @MassEOHED\n",
      "at opening celebra… 4\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @PaulFMatthews: Huge day for @WPI @UMassMedical @Mass_Tech @GEHealthcare @MITREcorp &amp; @NIH @TweetWorcester @MassEOHED\n",
      "at opening celebra… 4\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @PaulFMatthews: Huge day for @WPI @UMassMedical @Mass_Tech @GEHealthcare @MITREcorp &amp; @NIH @TweetWorcester @MassEOHED\n",
      "at opening celebra… 4\n",
      "RT @PaulFMatthews: Huge day for @WPI @UMassMedical @Mass_Tech @GEHealthcare @MITREcorp &amp; @NIH @TweetWorcester @MassEOHED\n",
      "at opening celebra… 4\n",
      "Huge day for @WPI @UMassMedical @Mass_Tech @GEHealthcare @MITREcorp &amp; @NIH @TweetWorcester @MassEOHED\n",
      "at opening ce… https://t.co/a57IjFYjE8 4\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @WPI: Implementation of the #WPIPlan 50 years ago was many things: tense, frustrating, exhilarating, but most of all, revolutionary; its… 7\n",
      "RT @ThePrintIndia: WPI inflation rises to 2.59% in December due to increase in food prices\n",
      "\n",
      "https://t.co/oXxh5aZgq6 4\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @ThePrintIndia: WPI inflation rises to 2.59% in December due to increase in food prices\n",
      "\n",
      "https://t.co/oXxh5aZgq6 4\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Ankur_tiwari2: @ShekharGupta Retail inflation at 7.3% due to vegetable prices that should cool down. \n",
      "Core inflation still 3.7%. \n",
      "Under… 26\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @PTI_News: WPI inflation rises to 2.59 per cent in Dec from 0.58 per cent in Nov: Govt data 22\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @INCUPEast: गौर करने वाली बात है कि मांग में कमी के बावजूद महंगाई अनियंत्रित हो चुकी है, इसका साफ मतलब है कि अर्थव्यवस्था एक बहुत बड़े… 5\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @INCUPEast: गौर करने वाली बात है कि मांग में कमी के बावजूद महंगाई अनियंत्रित हो चुकी है, इसका साफ मतलब है कि अर्थव्यवस्था एक बहुत बड़े… 5\n",
      "RT @INCUPEast: गौर करने वाली बात है कि मांग में कमी के बावजूद महंगाई अनियंत्रित हो चुकी है, इसका साफ मतलब है कि अर्थव्यवस्था एक बहुत बड़े… 5\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @DIPPGOI: Headline inflation rate (provisional) based on WPI for December, 2019 stood at 2.59 %, as compared to 0.58 % in the month of N… 5\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @karanbhasin95: Recent rate cuts may tempt some to claim rate cuts may have had an impact but that would be absurd! \n",
      "\n",
      "A major reason for… 5\n",
      "गौर करने वाली बात है कि मांग में कमी के बावजूद महंगाई अनियंत्रित हो चुकी है, इसका साफ मतलब है कि अर्थव्यवस्था एक ब… https://t.co/dCVTpiYzQN 5\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Ankur_tiwari2: @ShekharGupta Retail inflation at 7.3% due to vegetable prices that should cool down. \n",
      "Core inflation still 3.7%. \n",
      "Under… 26\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @moneycontrolcom: #BREAKING | Govt releases December WPI Inflation: 2.59% vs 0.58% (MoM)\n",
      "\n",
      "👉Food Inflation at 11.05% vs 9.02%\n",
      "👉Primary Ar… 7\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @PTI_News: WPI inflation rises to 2.59 per cent in Dec from 0.58 per cent in Nov: Govt data 22\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Ankur_tiwari2: @ShekharGupta Retail inflation at 7.3% due to vegetable prices that should cool down. \n",
      "Core inflation still 3.7%. \n",
      "Under… 26\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @DIPPGOI: Headline inflation rate (provisional) based on WPI for December, 2019 stood at 2.59 %, as compared to 0.58 % in the month of N… 5\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n",
      "RT @Sanju_Verma_: #CPI for Dec'19 is 7.35%,due to abnormal rise in #Onion prices which have since cooled off&amp;will be reflected in lower Jan… 178\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "def find_popular_tweets(twitter_api, statuses, retweet_threshold=3):\n",
    "\n",
    "    # You could also consider using the favorite_count parameter as part of\n",
    "    # this heuristic, possibly using it to provide an additional boost to\n",
    "    # popular tweets in a ranked formulation\n",
    "\n",
    "    return [ status\n",
    "                for status in statuses\n",
    "                    if status['retweet_count'] > retweet_threshold ]\n",
    "\n",
    "# Sample usage\n",
    "\n",
    "popular_tweets = find_popular_tweets(twitter_api, results)\n",
    "\n",
    "for tweet in popular_tweets:\n",
    "    print(tweet['text'], tweet['retweet_count'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Find the most popular Tweet Entities in your collection of tweets**\n",
    "\n",
    "Please plot a table of the top 10 hashtags, top 10 user mentions that are the most popular in your collection of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      " \"ZeeBusiness\",\n",
      " \"Sanju_Verma_\",\n",
      " \"PChidambaram_IN\",\n",
      " \"Ankur_tiwari2\",\n",
      " \"ShekharGupta\"\n",
      "]\n",
      "[\n",
      " \"CPI\",\n",
      " \"Onion\",\n",
      " \"CPI\",\n",
      " \"Onion\",\n",
      " \"practicepoint\"\n",
      "]\n",
      "[\n",
      " \"https://twitter.com/i/web/status/1217104140301586432\",\n",
      " \"https://twitter.com/i/web/status/1217103774835081216\",\n",
      " \"http://wpi.today/practicepoint\",\n",
      " \"http://wpi.today/practicepoint\",\n",
      " \"https://twitter.com/i/web/status/1217101084956798979\"\n",
      "]\n",
      "[\n",
      " \"https://t.co/QKrp7PDO9Z\",\n",
      " \"https://t.co/QKrp7PDO9Z\",\n",
      " \"https://t.co/PzsDpl1ZMN\",\n",
      " \"https://t.co/43HHQS80QX\",\n",
      " \"https://t.co/vnhsTmBlGf\"\n",
      "]\n",
      "[]\n",
      "Most common tweet entities\n",
      "[('CPI', 108), ('Onion', 108), ('Sanju_Verma_', 106), ('WPI', 27), ('Mass_Tech', 14), ('LaurieofMars', 10), ('MassEOHED', 9), ('UMassMedical', 5), ('GEHealthcare', 5), ('MITREcorp', 5), ('NIH', 5), ('TweetWorcester', 5), ('Ankur_tiwari2', 4), ('ShekharGupta', 4), ('PaulFMatthews', 4), ('mrirobot', 3), ('MikeAhernWPI', 3), ('bostonsci', 3), ('MarlboroughMA', 3), ('BREAKING', 3), ('INCUPEast', 3)]\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def extract_tweet_entities(statuses):\n",
    "\n",
    "    # See https://bit.ly/2MELMkm\n",
    "    # for more details on tweet entities\n",
    "\n",
    "    if len(statuses) == 0:\n",
    "        return [], [], [], [], []\n",
    "\n",
    "    screen_names = [ user_mention['screen_name']\n",
    "                         for status in statuses\n",
    "                            for user_mention in status['entities']['user_mentions'] ]\n",
    "\n",
    "    hashtags = [ hashtag['text']\n",
    "                     for status in statuses\n",
    "                        for hashtag in status['entities']['hashtags'] ]\n",
    "\n",
    "    urls = [ url['expanded_url']\n",
    "                     for status in statuses\n",
    "                        for url in status['entities']['urls'] ]\n",
    "\n",
    "    # In some circumstances (such as search results), the media entity\n",
    "    # may not appear\n",
    "    medias = []\n",
    "    symbols = []\n",
    "    for status in statuses:\n",
    "        if 'media' in status['entities']:\n",
    "            for media in status['entities']['media']:\n",
    "                medias.append(media['url'])\n",
    "        if 'symbol' in status['entities']:\n",
    "            for symbol in status['entities']['symbol']:\n",
    "                symbols.append(symbol)\n",
    "\n",
    "    return screen_names, hashtags, urls, medias, symbols\n",
    "\n",
    "# Sample usage\n",
    "screen_names, hashtags, urls, media, symbols = extract_tweet_entities(results)\n",
    "\n",
    "# Explore the first five items for each...\n",
    "\n",
    "print(json.dumps(screen_names[0:5], indent=1))\n",
    "print(json.dumps(hashtags[0:5], indent=1))\n",
    "print(json.dumps(urls[0:5], indent=1))\n",
    "print(json.dumps(media[0:5], indent=1))\n",
    "print(json.dumps(symbols[0:5], indent=1))\n",
    "\n",
    "def get_common_tweet_entities(statuses, entity_threshold=3):\n",
    "\n",
    "    # Create a flat list of all tweet entities\n",
    "    tweet_entities = [  e\n",
    "                        for status in statuses\n",
    "                            for entity_type in extract_tweet_entities([status])\n",
    "                                for e in entity_type\n",
    "                     ]\n",
    "\n",
    "    c = Counter(tweet_entities).most_common()\n",
    "\n",
    "    # Compute frequencies\n",
    "    return [ (k,v)\n",
    "             for (k,v) in c\n",
    "                 if v >= entity_threshold\n",
    "           ]\n",
    "\n",
    "# Sample usage\n",
    "common_entities = get_common_tweet_entities(results)\n",
    "\n",
    "print(\"Most common tweet entities\")\n",
    "print(common_entities)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ------------------------\n",
    "\n",
    "# Problem 3: Getting \"All\" friends and \"All\" followers of a popular user in twitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* choose a popular twitter user who has many followers, such as \"ladygaga\".\n",
    "* Get the list of all friends and all followers of the twitter user.\n",
    "* Plot 20 out of the followers, plot their ID numbers and screen names in a table.\n",
    "* Plot 20 out of the friends (if the user has more than 20 friends), plot their ID numbers and screen names in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      " {\n",
      "  \"id\": 132373965,\n",
      "  \"id_str\": \"132373965\",\n",
      "  \"name\": \"MiningTheSocialWeb\",\n",
      "  \"screen_name\": \"SocialWebMining\",\n",
      "  \"location\": \"\",\n",
      "  \"description\": \"Get the source code at GitHub: http://t.co/U0VmWrXpB9\",\n",
      "  \"url\": \"http://t.co/CJfJDyM6ki\",\n",
      "  \"entities\": {\n",
      "   \"url\": {\n",
      "    \"urls\": [\n",
      "     {\n",
      "      \"url\": \"http://t.co/CJfJDyM6ki\",\n",
      "      \"expanded_url\": \"http://miningthesocialweb.com\",\n",
      "      \"display_url\": \"miningthesocialweb.com\",\n",
      "      \"indices\": [\n",
      "       0,\n",
      "       22\n",
      "      ]\n",
      "     }\n",
      "    ]\n",
      "   },\n",
      "   \"description\": {\n",
      "    \"urls\": [\n",
      "     {\n",
      "      \"url\": \"http://t.co/U0VmWrXpB9\",\n",
      "      \"expanded_url\": \"http://bit.ly/MiningTheSocialWeb2E\",\n",
      "      \"display_url\": \"bit.ly/MiningTheSocia\\u2026\",\n",
      "      \"indices\": [\n",
      "       31,\n",
      "       53\n",
      "      ]\n",
      "     }\n",
      "    ]\n",
      "   }\n",
      "  },\n",
      "  \"protected\": false,\n",
      "  \"followers_count\": 4355,\n",
      "  \"friends_count\": 0,\n",
      "  \"listed_count\": 215,\n",
      "  \"created_at\": \"Tue Apr 13 02:10:40 +0000 2010\",\n",
      "  \"favourites_count\": 34,\n",
      "  \"utc_offset\": null,\n",
      "  \"time_zone\": null,\n",
      "  \"geo_enabled\": false,\n",
      "  \"verified\": false,\n",
      "  \"statuses_count\": 779,\n",
      "  \"lang\": null,\n",
      "  \"status\": {\n",
      "   \"created_at\": \"Mon Jan 28 14:06:01 +0000 2019\",\n",
      "   \"id\": 1089887323116969985,\n",
      "   \"id_str\": \"1089887323116969985\",\n",
      "   \"text\": \"What did it take to write the new edition? Well, trying to keep up with a changing social media landscape, for one.\\u2026 https://t.co/vsaR6B4smZ\",\n",
      "   \"truncated\": true,\n",
      "   \"entities\": {\n",
      "    \"hashtags\": [],\n",
      "    \"symbols\": [],\n",
      "    \"user_mentions\": [],\n",
      "    \"urls\": [\n",
      "     {\n",
      "      \"url\": \"https://t.co/vsaR6B4smZ\",\n",
      "      \"expanded_url\": \"https://twitter.com/i/web/status/1089887323116969985\",\n",
      "      \"display_url\": \"twitter.com/i/web/status/1\\u2026\",\n",
      "      \"indices\": [\n",
      "       117,\n",
      "       140\n",
      "      ]\n",
      "     }\n",
      "    ]\n",
      "   },\n",
      "   \"source\": \"<a href=\\\"https://buffer.com\\\" rel=\\\"nofollow\\\">Buffer</a>\",\n",
      "   \"in_reply_to_status_id\": null,\n",
      "   \"in_reply_to_status_id_str\": null,\n",
      "   \"in_reply_to_user_id\": null,\n",
      "   \"in_reply_to_user_id_str\": null,\n",
      "   \"in_reply_to_screen_name\": null,\n",
      "   \"geo\": null,\n",
      "   \"coordinates\": null,\n",
      "   \"place\": null,\n",
      "   \"contributors\": null,\n",
      "   \"is_quote_status\": false,\n",
      "   \"retweet_count\": 4,\n",
      "   \"favorite_count\": 14,\n",
      "   \"favorited\": false,\n",
      "   \"retweeted\": false,\n",
      "   \"possibly_sensitive\": false,\n",
      "   \"lang\": \"en\"\n",
      "  },\n",
      "  \"contributors_enabled\": false,\n",
      "  \"is_translator\": false,\n",
      "  \"is_translation_enabled\": false,\n",
      "  \"profile_background_color\": \"352726\",\n",
      "  \"profile_background_image_url\": \"http://abs.twimg.com/images/themes/theme5/bg.gif\",\n",
      "  \"profile_background_image_url_https\": \"https://abs.twimg.com/images/themes/theme5/bg.gif\",\n",
      "  \"profile_background_tile\": false,\n",
      "  \"profile_image_url\": \"http://pbs.twimg.com/profile_images/1154493071/Picture_7_normal.png\",\n",
      "  \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/1154493071/Picture_7_normal.png\",\n",
      "  \"profile_link_color\": \"D02B55\",\n",
      "  \"profile_sidebar_border_color\": \"829D5E\",\n",
      "  \"profile_sidebar_fill_color\": \"99CC33\",\n",
      "  \"profile_text_color\": \"3E4415\",\n",
      "  \"profile_use_background_image\": true,\n",
      "  \"has_extended_profile\": false,\n",
      "  \"default_profile\": false,\n",
      "  \"default_profile_image\": false,\n",
      "  \"can_media_tag\": true,\n",
      "  \"followed_by\": false,\n",
      "  \"following\": false,\n",
      "  \"follow_request_sent\": false,\n",
      "  \"notifications\": false,\n",
      "  \"translator_type\": \"none\"\n",
      " }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "from urllib.error import URLError\n",
    "from http.client import BadStatusLine\n",
    "import json\n",
    "import twitter\n",
    "\n",
    "def make_twitter_request(twitter_api_func, max_errors=10, *args, **kw):\n",
    "\n",
    "    # A nested helper function that handles common HTTPErrors. Returns an updated\n",
    "    # value for wait_period if the problem is a 500-level error. Blocks until the\n",
    "    # rate limit is reset if it's a rate-limiting issue (429 error). Returns None\n",
    "    # for 401 and 404 errors, which require special handling by the caller.\n",
    "    def handle_twitter_http_error(e, wait_period=2, sleep_when_rate_limited=True):\n",
    "\n",
    "        if wait_period > 3600: # Seconds\n",
    "            print('Too many retries. Quitting.', file=sys.stderr)\n",
    "            raise e\n",
    "\n",
    "        # See https://developer.twitter.com/en/docs/basics/response-codes\n",
    "        # for common codes\n",
    "\n",
    "        if e.e.code == 401:\n",
    "            print('Encountered 401 Error (Not Authorized)', file=sys.stderr)\n",
    "            return None\n",
    "        elif e.e.code == 404:\n",
    "            print('Encountered 404 Error (Not Found)', file=sys.stderr)\n",
    "            return None\n",
    "        elif e.e.code == 429:\n",
    "            print('Encountered 429 Error (Rate Limit Exceeded)', file=sys.stderr)\n",
    "            if sleep_when_rate_limited:\n",
    "                print(\"Retrying in 15 minutes...ZzZ...\", file=sys.stderr)\n",
    "                sys.stderr.flush()\n",
    "                time.sleep(60*15 + 5)\n",
    "                print('...ZzZ...Awake now and trying again.', file=sys.stderr)\n",
    "                return 2\n",
    "            else:\n",
    "                raise e # Caller must handle the rate-limiting issue\n",
    "        elif e.e.code in (500, 502, 503, 504):\n",
    "            print('Encountered {0} Error. Retrying in {1} seconds'\\\n",
    "                  .format(e.e.code, wait_period), file=sys.stderr)\n",
    "            time.sleep(wait_period)\n",
    "            wait_period *= 1.5\n",
    "            return wait_period\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "    # End of nested helper function\n",
    "\n",
    "    wait_period = 2\n",
    "    error_count = 0\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            return twitter_api_func(*args, **kw)\n",
    "        except twitter.api.TwitterHTTPError as e:\n",
    "            error_count = 0\n",
    "            wait_period = handle_twitter_http_error(e, wait_period)\n",
    "            if wait_period is None:\n",
    "                return\n",
    "        except URLError as e:\n",
    "            error_count += 1\n",
    "            time.sleep(wait_period)\n",
    "            wait_period *= 1.5\n",
    "            print(\"URLError encountered. Continuing.\", file=sys.stderr)\n",
    "            if error_count > max_errors:\n",
    "                print(\"Too many consecutive errors...bailing out.\", file=sys.stderr)\n",
    "                raise\n",
    "        except BadStatusLine as e:\n",
    "            error_count += 1\n",
    "            time.sleep(wait_period)\n",
    "            wait_period *= 1.5\n",
    "            print(\"BadStatusLine encountered. Continuing.\", file=sys.stderr)\n",
    "            if error_count > max_errors:\n",
    "                print(\"Too many consecutive errors...bailing out.\", file=sys.stderr)\n",
    "                raise\n",
    "\n",
    "# Sample usage\n",
    "\n",
    "twitter_api = oauth_login()\n",
    "\n",
    "# See http://bit.ly/2Gcjfzr for twitter_api.users.lookup\n",
    "\n",
    "response = make_twitter_request(twitter_api.users.lookup,\n",
    "                                screen_name=\"SocialWebMining\")\n",
    "\n",
    "print(json.dumps(response, indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetched 5000 total friends ids for ladygaga\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[398484165, 59523299, 168913538, 54874849, 17140848, 61676732, 42223630, 405201832, 137361325, 71958723, 847230698381484032, 33629154, 896302694, 3004549757, 194277529, 3272078402, 298337938, 936867551606276096, 1446170412, 70132146, 3284679223, 1570940906, 1325139061, 2782048099, 14055301, 2569348549, 518559069, 468865085, 2453058606, 23941831, 398177111, 2340995954, 252497457, 3227842905, 799368758, 846474679, 3164564393, 16573941, 14235543, 217326533, 799434452581617668, 142116606, 252795535, 29417304, 755113, 74457103, 1668851430, 2485170618, 81255511, 1886497470, 773871286477066240, 84280889, 759798284344963073, 4858376775, 215469746, 800009595141885952, 22201002, 34704331, 2161631623, 3497941, 3289375408, 29442313, 1536791610, 822215679726100480, 216776631, 108471631, 3596882837, 79082441, 502789617, 2277106410, 490789927, 20793816, 311337372, 226733027, 43761917, 1567165010, 18518096, 276540738, 1356857802, 846672097, 630710500, 45709328, 160555528, 4657930739, 82968119, 24833643, 2200128141, 415821364, 28221296, 274072391, 776467500636729344, 549038792, 715345586438991872, 4889933608, 77792645, 2676872542, 600966138, 191607118, 704734783364997120, 766289917437734912]\n",
      "[1207407148428353537, 1216481394861281281, 882080756700524545, 1452574676, 1217103111816269826, 961679928260472838, 1211437554584576001, 3306535661, 1024866354048847872, 1216855724942192640, 1216150340921217025, 2821078432, 801931917457231872, 1217102114360643584, 1216736148128706561, 80997468, 1217103164131790848, 1178743517176356864, 1206455400775716864, 1194772717762994177, 1215650290554363906, 904670466245320705, 1054527603002896384, 977791743331454976, 4843237280, 933572988, 1216679058752274432, 1217101733710782464, 865809132665753600, 1202952223266877446, 1217087938347044865, 1214263982820708353, 1217102427188535297, 1217038790998577152, 1216825526284955649, 1171426471581118464, 950895715114418176, 1216457330902081536, 1205623343614959616, 1217093185043750914, 499817249, 1217100821898452992, 1217098836411371520, 1177383050214133760, 198731587, 1216458516463964161, 254878692, 1217101765453254657, 995814640016855040, 1216851489303539712, 1217100938881785856, 1217099584578760704, 1215683909792489477, 1436217180, 1217100503596879878, 1217088492670541830, 1217097319453220864, 1217098911384580101, 1129359770866081794, 1123604433307303938, 1149420569026355201, 1215977447226839040, 1217100687642910721, 603901962, 1217058975755198464, 1216780951990173696, 1216489556964446210, 374600715, 1162623063734784001, 1217099932030701569, 1215268934221475841, 1216057476514304000, 1217099721237520390, 1216312636884836353, 1217096768728363009, 1180505005004066816, 1217099871951319052, 1167418477382029312, 1213844506128183296, 1146040966740172800, 1096539454087536640, 1216899223247081472, 3854846716, 1217097172333756416, 1095972085799809024, 1105895645905408000, 997617897089388544, 4390291299, 1099743158274048002, 1217069168710864896, 1126612249483927562, 1217096581855481857, 1214702892373950465, 4191544460, 1216530934532595713, 966749766548893697, 1217094077688082432, 1217053875049574400, 1208808728973250560, 1216215589527543808]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetched 5000 total followers ids for ladygaga\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "from functools import partial\n",
    "from sys import maxsize as maxint\n",
    "\n",
    "def get_friends_followers_ids(twitter_api, screen_name=None, user_id=None,\n",
    "                              friends_limit=maxint, followers_limit=maxint):\n",
    "\n",
    "    # Must have either screen_name or user_id (logical xor)\n",
    "    assert (screen_name != None) != (user_id != None), \"Must have screen_name or user_id, but not both\"\n",
    "\n",
    "    # See http://bit.ly/2GcjKJP and http://bit.ly/2rFz90N for details\n",
    "    # on API parameters\n",
    "\n",
    "    get_friends_ids = partial(make_twitter_request, twitter_api.friends.ids,\n",
    "                              count=5000)\n",
    "    get_followers_ids = partial(make_twitter_request, twitter_api.followers.ids,\n",
    "                                count=5000)\n",
    "\n",
    "    friends_ids, followers_ids = [], []\n",
    "\n",
    "    for twitter_api_func, limit, ids, label in [\n",
    "                    [get_friends_ids, friends_limit, friends_ids, \"friends\"],\n",
    "                    [get_followers_ids, followers_limit, followers_ids, \"followers\"]\n",
    "                ]:\n",
    "\n",
    "        if limit == 0: continue\n",
    "\n",
    "        cursor = -1\n",
    "        while cursor != 0:\n",
    "\n",
    "            # Use make_twitter_request via the partially bound callable\n",
    "            if screen_name:\n",
    "                response = twitter_api_func(screen_name=screen_name, cursor=cursor)\n",
    "            else: # user_id\n",
    "                response = twitter_api_func(user_id=user_id, cursor=cursor)\n",
    "\n",
    "            if response is not None:\n",
    "                ids += response['ids']\n",
    "                cursor = response['next_cursor']\n",
    "\n",
    "            print('Fetched {0} total {1} ids for {2}'.format(len(ids),\n",
    "                  label, (user_id or screen_name)),file=sys.stderr)\n",
    "\n",
    "            # You may want to store data during each iteration to provide an\n",
    "            # additional layer of protection from exceptional circumstances\n",
    "\n",
    "            if len(ids) >= limit or response is None:\n",
    "                break\n",
    "\n",
    "    # Do something useful with the IDs, like store them to disk\n",
    "    return friends_ids[:friends_limit], followers_ids[:followers_limit]\n",
    "\n",
    "# Sample usage\n",
    "\n",
    "twitter_api = oauth_login()\n",
    "\n",
    "friends_ids, followers_ids = get_friends_followers_ids(twitter_api,\n",
    "                                                       screen_name=\"ladygaga\",\n",
    "                                                       friends_limit=100,\n",
    "                                                       followers_limit=100)\n",
    "\n",
    "print(friends_ids)\n",
    "print(followers_ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute the mutual friends within the two groups, i.e., the users who are in both friend list and follower list, plot their ID numbers and screen names in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetched 5000 total friends ids for ladygaga\n",
      "Fetched 5000 total followers ids for ladygaga\n",
      "Fetched 18 total friends ids for randypaffenroth\n",
      "Fetched 26 total followers ids for randypaffenroth\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "\n",
    "# Sample usage\n",
    "\n",
    "twitter_api = oauth_login()\n",
    "\n",
    "friends_ids_1, followers_ids_1 = get_friends_followers_ids(twitter_api,\n",
    "                                                       screen_name=\"ladygaga\",\n",
    "                                                       friends_limit=100,\n",
    "                                                       followers_limit=100)\n",
    "friends_ids_2, followers_ids_2 = get_friends_followers_ids(twitter_api,\n",
    "                                                       screen_name=\"randypaffenroth\",\n",
    "                                                       friends_limit=100,\n",
    "                                                       followers_limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "friends_ids_1 = set(friends_ids_1)\n",
    "followers_ids_1 = set(followers_ids_1)\n",
    "friends_ids_2 = set(friends_ids_2)\n",
    "followers_ids_2 = set(followers_ids_2)\n",
    "\n",
    "print(friends_ids_1.intersection(friends_ids_2))\n",
    "print(followers_ids_1.intersection(followers_ids_2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*------------------------\n",
    "\n",
    "# Problem 4: Business question \n",
    "\n",
    "Run some additional experiments with your data to gain familiarity with the twitter data and twitter API.\n",
    "\n",
    "* Come up with a business question that Twitter data could help answer.\n",
    "* Decribe the business case.\n",
    "* How could Twitter data help a company decide how to spend its resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*-----------------\n",
    "# Done\n",
    "\n",
    "All set! \n",
    "\n",
    "** What do you need to submit?**\n",
    "\n",
    "* **Notebook File**: Save this IPython notebook, and find the notebook file in your folder (for example, \"filename.ipynb\"). This is the file you need to submit. Please make sure all the plotted tables and figures are in the notebook. If you used \"ipython notebook --pylab=inline\" to open the notebook, all the figures and tables should have shown up in the notebook.\n",
    "\n",
    "\n",
    "* **PPT Slides**: please prepare PPT slides (for 15 minutes' talk) to present about the case study . We will ask two teams which are randomly selected to present their case studies in class for this case study. \n",
    "\n",
    "* ** Report**: please prepare a report (less than 10 pages) to report what you found in the data.\n",
    "    * What data you collected? \n",
    "    * Why this topic is interesting or important to you? (Motivations)\n",
    "    * How did you analyse the data?\n",
    "    * What did you find in the data? \n",
    " \n",
    "     (please include figures or tables in the report, but no source code)\n",
    "\n",
    "Please compress all the files in a zipped file.\n",
    "\n",
    "\n",
    "** How to submit: **\n",
    "\n",
    "        Please submit through email to Prof. Paffenroth (rcpaffenroth@wpi.edu).\n",
    "\n",
    "#### We auto-process the submissions so make sure your subject line is *exactly*:\n",
    "\n",
    "### DS3010 Case Study 1 Team ??\n",
    "\n",
    "#### where ?? is your team number.\n",
    "        \n",
    "** Note: Each team just needs to submits one submission **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grading Criteria:\n",
    "\n",
    "** Totoal Points: 100 **\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "** Notebook results:  **\n",
    "    Points: 80\n",
    "\n",
    "\n",
    "    -----------------------------------\n",
    "    Qestion 1:\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "    \n",
    "    (1) Select a topic that you are interested in.\n",
    "    Points: 6 \n",
    "    \n",
    "    (2) Use Twitter Streaming API to sample a collection of tweets about this topic in real time. (It would be recommended that the number of tweets should be larger than 200, but smaller than 1 million. Please check whether the total number of tweets collected is larger than 200?\n",
    "    Points: 10 \n",
    "    \n",
    "    \n",
    "    (3) Store the tweets you downloaded into a local file (txt file or json file)\n",
    "    Points: 4 \n",
    "    \n",
    "    \n",
    "    -----------------------------------\n",
    "    Qestion 2:\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "    \n",
    "    1. Word Count\n",
    "\n",
    "    (1) Use the tweets you collected in Problem 1, and compute the frequencies of the words being used in these tweets.\n",
    "    Points: 4 \n",
    "\n",
    "    (2) Plot a table of the top 30 words with their counts \n",
    "    Points: 4 \n",
    "    \n",
    "    2. Find the most popular tweets in your collection of tweets\n",
    "    plot a table of the top 10 tweets that are the most popular among your collection, i.e., the tweets with the largest number of retweet counts.\n",
    "    Points: 4 \n",
    "    \n",
    "    3. Find the most popular Tweet Entities in your collection of tweets\n",
    "\n",
    "    (1) plot a table of the top 10 hashtags, \n",
    "    Points: 4 \n",
    "\n",
    "    (2) top 10 user mentions that are the most popular in your collection of tweets.\n",
    "    Points: 4 \n",
    "    \n",
    "    \n",
    "    -----------------------------------\n",
    "    Qestion 3:\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "    \n",
    "    (1) choose a popular twitter user who has many followers, such as \"ladygaga\".\n",
    "    Points: 4 \n",
    "\n",
    "    (2) Get the list of all friends and all followers of the twitter user.\n",
    "    Points: 4 \n",
    "\n",
    "    (3) Plot 20 out of the followers, plot their ID numbers and screen names in a table.\n",
    "    Points: 4 \n",
    "\n",
    "    (4) Plot 20 out of the friends (if the user has more than 20 friends), plot their ID numbers and screen names in a table.\n",
    "    Points: 4 \n",
    "    \n",
    "    (5) Compute the mutual friends within the two groups, i.e., the users who are in both friend list and follower list, plot their ID numbers and screen names in a table\n",
    "    Points: 4 \n",
    "  \n",
    "    -----------------------------------\n",
    "    Qestion 4:  Business question\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "        Novelty: 10\n",
    "        Interestingness: 10\n",
    "    -----------------------------------\n",
    "    Run some additional experiments with your data to gain familiarity with the twitter data ant twitter API.  Come up with a business question and describe how Twitter data can help you answer that question.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "** Slides (for 10 minutes of presentation): Story-telling **\n",
    "    Points: 20\n",
    "\n",
    "\n",
    "1. Motivation about the data collection, why the topic is interesting to you.\n",
    "    Points: 5 \n",
    "\n",
    "2. Communicating Results (figure/table)\n",
    "    Points: 10 \n",
    "\n",
    "3. Story telling (How all the parts (data, analysis, result) fit together as a story?)\n",
    "    Points: 5 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nteract": {
   "version": "0.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
